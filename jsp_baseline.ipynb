{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8bc20e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from ortools.sat.python import cp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecbcf89",
   "metadata": {},
   "source": [
    "Options:\n",
    "\n",
    "1) function that transforms a path into job data structure\n",
    "    * this will only evaluate the scheduling effort of our method\n",
    "2) change our method to use the added constraints of machine assignement\n",
    "    * does this make the problem harder or easier?\n",
    "    * link prediction on the \"next\" arrows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95027d7",
   "metadata": {},
   "source": [
    "#### Minimal jobshop problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb434589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g2jobdata(g0, a):\n",
    "    \"\"\"\n",
    "    Reformat data such that CPModel can solve for the optimal MakeSpan.\n",
    "    \n",
    "    a : list of action tuples as recieved from MDP path sampler\n",
    "    g0: initial g as returned from env.reset()\n",
    "    \n",
    "    From action log get sequence of assignments and get times from node features.\n",
    "    Then deduce jobs (sequence of operations) and store in data log.\n",
    "    \n",
    "    Example format:\n",
    "    jobs_data = [  # task = (machine_id, processing_time).\n",
    "        [(0, 3), (1, 2), (2, 2)],  # Job0\n",
    "        [(0, 2), (2, 1), (1, 4)],  # Job1\n",
    "        [(1, 4), (2, 3)]  # Job2\n",
    "    ]\n",
    "    \"\"\"\n",
    "    \n",
    "    a = torch.tensor(a)\n",
    "    assignments = a[a[:, 1].argsort()][:, 0]\n",
    "    times = g0.ndata['hv']['job'][:, 0].div(0.1, rounding_mode='trunc').int().tolist()\n",
    "    \n",
    "    jobs_data = []\n",
    "    prev_j = -1\n",
    "    for (i, j) in torch.stack(g0.edges(etype=\"precede\")).T.tolist():\n",
    "        if prev_j != i:\n",
    "            jobs_data.append([(assignment[i], times[i])])\n",
    "        jobs_data[-1].append((assignment[j], times[j]))\n",
    "        prev_j = j\n",
    "\n",
    "    single_jobs = [i for i in range(g0.num_nodes('job')) if i not in torch.stack(g0.edges(etype=\"precede\")).unique()]\n",
    "    for i in single_jobs:\n",
    "        jobs_data.append([(assignment[i], times[i])])\n",
    "\n",
    "    return jobs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81269767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named tuple to store information about created variables.\n",
    "task_type = collections.namedtuple('task_type', 'start end interval')\n",
    "# Named tuple to manipulate solution information.\n",
    "assigned_task_type = collections.namedtuple('assigned_task_type',\n",
    "                                            'start job index duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56065bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_makespan(jobs_data, verbose=False):\n",
    "    \n",
    "    machines_count = 1 + max(task[0] for job in jobs_data for task in job)\n",
    "    all_machines = range(machines_count)\n",
    "    horizon = sum(task[1] for job in jobs_data for task in job)\n",
    "\n",
    "    model = cp_model.CpModel()\n",
    "\n",
    "    # Creates job intervals and add to the corresponding machine lists.\n",
    "    all_tasks = {}\n",
    "    machine_to_intervals = collections.defaultdict(list)\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id, task in enumerate(job):\n",
    "            machine = task[0]\n",
    "            duration = task[1]\n",
    "            suffix = '_%i_%i' % (job_id, task_id)\n",
    "            start_var = model.NewIntVar(0, horizon, 'start' + suffix)\n",
    "            end_var = model.NewIntVar(0, horizon, 'end' + suffix)\n",
    "            interval_var = model.NewIntervalVar(start_var, duration, end_var,\n",
    "                                                'interval' + suffix)\n",
    "            all_tasks[job_id, task_id] = task_type(start=start_var,\n",
    "                                                   end=end_var,\n",
    "                                                   interval=interval_var)\n",
    "            machine_to_intervals[machine].append(interval_var)\n",
    "\n",
    "    # Create and add disjunctive constraints.\n",
    "    for machine in all_machines:\n",
    "        model.AddNoOverlap(machine_to_intervals[machine])\n",
    "\n",
    "    # Precedences inside a job.\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id in range(len(job) - 1):\n",
    "            model.Add(all_tasks[job_id, task_id +\n",
    "                                1].start >= all_tasks[job_id, task_id].end)\n",
    "\n",
    "\n",
    "    # Makespan objective.\n",
    "    obj_var = model.NewIntVar(0, horizon, 'makespan')\n",
    "    model.AddMaxEquality(obj_var, [\n",
    "        all_tasks[job_id, len(job) - 1].end\n",
    "        for job_id, job in enumerate(jobs_data)\n",
    "    ])\n",
    "    model.Minimize(obj_var)\n",
    "\n",
    "    # Creates the solver and solve.\n",
    "    solver = cp_model.CpSolver()\n",
    "    status = solver.Solve(model)\n",
    "\n",
    "    if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "        if verbose:\n",
    "            print('Solution:')\n",
    "            # Create one list of assigned tasks per machine.\n",
    "            assigned_jobs = collections.defaultdict(list)\n",
    "            for job_id, job in enumerate(jobs_data):\n",
    "                for task_id, task in enumerate(job):\n",
    "                    machine = task[0]\n",
    "                    assigned_jobs[machine].append(\n",
    "                        assigned_task_type(start=solver.Value(\n",
    "                            all_tasks[job_id, task_id].start),\n",
    "                                           job=job_id,\n",
    "                                           index=task_id,\n",
    "                                           duration=task[1]))\n",
    "\n",
    "            # Create per machine output lines.\n",
    "            output = ''\n",
    "            for machine in all_machines:\n",
    "                # Sort by starting time.\n",
    "                assigned_jobs[machine].sort()\n",
    "                sol_line_tasks = 'Machine ' + str(machine) + ': '\n",
    "                sol_line = '           '\n",
    "\n",
    "                for assigned_task in assigned_jobs[machine]:\n",
    "                    name = 'job_%i_task_%i' % (assigned_task.job,\n",
    "                                               assigned_task.index)\n",
    "                    # Add spaces to output to align columns.\n",
    "                    sol_line_tasks += '%-15s' % name\n",
    "\n",
    "                    start = assigned_task.start\n",
    "                    duration = assigned_task.duration\n",
    "                    sol_tmp = '[%i,%i]' % (start, start + duration)\n",
    "                    # Add spaces to output to align columns.\n",
    "                    sol_line += '%-15s' % sol_tmp\n",
    "\n",
    "                sol_line += '\\n'\n",
    "                sol_line_tasks += '\\n'\n",
    "                output += sol_line_tasks\n",
    "                output += sol_line\n",
    "\n",
    "            # Finally print the solution found.\n",
    "            print(f'Optimal Schedule Length: {solver.ObjectiveValue()}')\n",
    "            print(output)\n",
    "        \n",
    "        return solver.ObjectiveValue(), \"OPTIMAL\" if status==cp_model.OPTIMAL else \"FEASIBLE\"\n",
    "            \n",
    "    if verbose:\n",
    "        print('No solution found.')\n",
    "        print('\\nStatistics')\n",
    "        print('  - conflicts: %i' % solver.NumConflicts())\n",
    "        print('  - branches : %i' % solver.NumBranches())\n",
    "        print('  - wall time: %f s' % solver.WallTime())\n",
    "        \n",
    "    return -1, \"INFEASIBLE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21064514",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, status = get_makespan(jobs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6c678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rlpyt] *",
   "language": "python",
   "name": "conda-env-rlpyt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
