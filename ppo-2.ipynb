{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4c5353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/victorialena/rlkit')\n",
    "\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import rlkit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from actor.collision_avoidance import *\n",
    "from actor.actor_critic import *\n",
    "from env.collision_avoidance import *\n",
    "from replay_buffer import PPOBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f08ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.seed = 0\n",
    "        self.c_hidden = [64, 8]\n",
    "        self.n_linear = 1\n",
    "        self.eps = 0.1 \n",
    "        self.sim_annealing_fac = 1.0 \n",
    "        self.replay_buffer_cap = 1000\n",
    "        self.n_samples = 1 #100\n",
    "        self.prioritized_replay = True\n",
    "        self.learning_rate = 1E-4 #1E-3\n",
    "        self.n_epoch = 300\n",
    "        self.n_iter = 128 \n",
    "        self.batch_size = 64\n",
    "        self.gamma = 0.98\n",
    "        self.dropout = 0. #0.01\n",
    "        self.max_ep_len = 1000\n",
    "\n",
    "        self.graph_type = \"full\" \n",
    "        self.load_from = \"\"\n",
    "        self.save_to = \"\"\n",
    "        self.plot = True\n",
    "        self.plot_name = \"\"\n",
    "        self.max_sample_distance = -1\n",
    "\n",
    "        self.maze_size = 5 \n",
    "        self.ndrones = 4\n",
    "        self.ngoals = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3061bba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ffba980",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "def _rot_b2i(X):\n",
    "    abc = [rot_b2i(*x) for x in X]\n",
    "    return torch.matmul(torch.stack(abc), torch.tensor([1.,0,0]))\n",
    "\n",
    "def plot_path(obs, c_name='cividis'):\n",
    "    cmap = cm.get_cmap(c_name)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    # Data for a three-dimensional line\n",
    "    obs = torch.stack([o.x[:, :3] for o in obs]).swapaxes(1,0) # shape (N, nd, 3)\n",
    "    np.random.seed(42)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    ax.set_title('Trajectories')\n",
    "    for _ in obs:\n",
    "        xp, yp, zp = _.T\n",
    "        ax.plot3D(xp, yp, zp, color=cmap(np.random.rand()))        \n",
    "    return fig, ax\n",
    "\n",
    "def plot_pos(obs, ax = None):\n",
    "    if ax == None:\n",
    "        ax = plt.axes(projection='3d')\n",
    "    \n",
    "    # Data for three-dimensional scattered points\n",
    "    xp, yp, zp, _, _, _, v = obs.x.T\n",
    "    u, v, w = _rot_b2i(obs.x[:, 3:-1]).T\n",
    "    ax.scatter3D(xp, yp, zp);\n",
    "    # ax.quiver(xp, y, z, u, v, w, length=1000, normalize=True)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6444b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "device = 'cpu' #torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "env = collisionAvoidance(args, device=device)\n",
    "x = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8178e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "env.seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a90ede",
   "metadata": {},
   "source": [
    "``` python\n",
    "from matplotlib import animation\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter \n",
    "\n",
    "def simple_animation(obs, saveas='collision_avoidance_1'):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plot_path(obs)\n",
    "    \n",
    "    def env_simple_update(num, obs, ax):\n",
    "        ax.clear()\n",
    "        plot_pos(obs[num])\n",
    "        ax.set_title(\"Frame {}\".format(num))\n",
    "    \n",
    "    ani = animation.FuncAnimation(fig, env_simple_update, frames=len(obs), fargs=(obs, ax))\n",
    "    ani.save(\"figs/drone_delivery/\"+saveas+'.gif', writer='imagemagick', \n",
    "             savefig_kwargs={'facecolor':'white'}, fps=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24322198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(env, nsteps):\n",
    "    o = env.reset()\n",
    "    obs = [o]\n",
    "    for _ in range(nsteps):\n",
    "        a = np.zeros((env.nagents, len(env.aspace.sample()))) #np.array([env.aspace.sample() for _ in range(env.nagents)])\n",
    "        next_o, _, _, _ = env.step(a)\n",
    "        obs.append(next_o)\n",
    "        o = next_o      \n",
    "        \n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be6312fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels, out_channels = env.get_channels()\n",
    "\n",
    "qf_v = collisionAvoidanceModel(in_channels, 1, args.c_hidden, n_linear=args.n_linear, \n",
    "                               bounds=env.get_size(), dropout=args.dropout)\n",
    "\n",
    "qf_pi = collisionAvoidanceModel(in_channels, out_channels, args.c_hidden, n_linear=args.n_linear, \n",
    "                                bounds=env.get_size(), dropout=args.dropout)\n",
    "\n",
    "ac = MLPActorCritic(qf_pi, qf_v);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e305d0",
   "metadata": {},
   "source": [
    "```python\n",
    "lam=0.97\n",
    "target_kl=0.01\n",
    "clip_ratio=0.2\n",
    "pi_lr=3e-4\n",
    "vf_lr=1e-3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc84cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo(env, actor_critic, args, \n",
    "        lam=0.97, target_kl=0.01, clip_ratio=0.2, pi_lr=3e-4, vf_lr=1e-3):    \n",
    "    \"\"\" Proximal Policy Optimization (by clipping), with early stopping based on approximate KL \"\"\"\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    env.seed(args.seed)\n",
    "\n",
    "    def compute_loss_pi(data):\n",
    "        obs, act, adv, logp_old = data['obs'], data['act'], data['adv'].unsqueeze(1), data['logp']\n",
    "        act = act.reshape(-1, act.shape[-1])\n",
    "        \n",
    "        # Policy loss\n",
    "        pi, logp = actor_critic.pi(obs, act)\n",
    "        logp = logp.reshape(logp_old.shape)\n",
    "        \n",
    "        ratio = torch.exp(logp - logp_old)\n",
    "        clip_adv = torch.clamp(ratio, 1-clip_ratio, 1+clip_ratio) * adv\n",
    "        loss_pi = -(torch.min(ratio * adv, clip_adv)).mean()\n",
    "\n",
    "        # Useful extra info\n",
    "        approx_kl = (logp_old - logp).mean().item()\n",
    "        ent = pi.entropy().mean().item()\n",
    "        clipped = ratio.gt(1+clip_ratio) | ratio.lt(1-clip_ratio)\n",
    "        clipfrac = torch.as_tensor(clipped, dtype=torch.float32).mean().item()\n",
    "        pi_info = dict(kl=approx_kl, ent=ent, cf=clipfrac)\n",
    "\n",
    "        return loss_pi, pi_info\n",
    "\n",
    "    def compute_loss_v(data):\n",
    "        obs, ret = data['obs'], data['ret']\n",
    "        return ((actor_critic.v(obs) - ret)**2).sum(1).mean()\n",
    "\n",
    "    pi_optimizer = Adam(actor_critic.pi.parameters(), lr=pi_lr)\n",
    "    vf_optimizer = Adam(actor_critic.v.parameters(), lr=vf_lr)\n",
    "\n",
    "    def update():\n",
    "        # TODO: should this be in the the training loop?\n",
    "        data = buf.get()\n",
    "\n",
    "        pi_l_old, pi_info_old = compute_loss_pi(data)\n",
    "        pi_l_old = pi_l_old.item()\n",
    "        v_l_old = compute_loss_v(data).item()\n",
    "\n",
    "        # Train policy with multiple steps of gradient descent\n",
    "        for i in range(args.n_iter):\n",
    "            pi_optimizer.zero_grad()\n",
    "            loss_pi, pi_info = compute_loss_pi(data)\n",
    "            kl = pi_info['kl'] # mpi_avg(pi_info['kl'])\n",
    "            if kl > 1.5 * target_kl:\n",
    "                break # Early stopping at step %d due to reaching max kl\n",
    "            loss_pi.backward()\n",
    "            # mpi_avg_grads(actor_critic.pi)    # average grads across MPI processes\n",
    "            pi_optimizer.step()\n",
    "\n",
    "        # Value function learning\n",
    "        for i in range(args.n_iter):\n",
    "            vf_optimizer.zero_grad()\n",
    "            loss_v = compute_loss_v(data)\n",
    "            loss_v.backward()\n",
    "            # mpi_avg_grads(actor_critic.v)    # average grads across MPI processes\n",
    "            vf_optimizer.step()\n",
    "\n",
    "        # Log changes from update\n",
    "        # kl, ent, cf = pi_info['kl'], pi_info_old['ent'], pi_info['cf']\n",
    "        return loss_pi.item(), loss_v.item()\n",
    "\n",
    "    o, ep_ret, ep_len = env.reset(), 0, 0\n",
    "    max_ep_len = args.max_ep_len\n",
    "    buf = PPOBuffer(args.n_samples*max_ep_len, # args.replay_buffer_cap, \n",
    "                    args.gamma, lam)\n",
    "\n",
    "    for epoch in range(args.n_epoch):\n",
    "        buf.clear()\n",
    "        actor_critic.train(True)\n",
    "        ret_train = []\n",
    "        for t in range(args.n_samples*max_ep_len):\n",
    "            if ep_len == 0:\n",
    "                buf.start_path()\n",
    "            a, v, logp = actor_critic.step(o)\n",
    "\n",
    "            next_o, r, d, _ = env.step(a)\n",
    "            ep_ret += r\n",
    "            ep_len += 1\n",
    "\n",
    "            # save and log\n",
    "            buf.add_sample(o, a, r, v, logp)\n",
    "\n",
    "            # Update obs (critical!)\n",
    "            o = next_o\n",
    "\n",
    "            timeout = ep_len == max_ep_len\n",
    "            terminal = d or timeout\n",
    "            epoch_ended = t == (args.n_samples*max_ep_len)-1\n",
    "\n",
    "            if terminal or epoch_ended:\n",
    "                ret_train.append(ep_ret.sum().item())\n",
    "                if epoch_ended and not(terminal):\n",
    "                    print('Warning: trajectory cut off by epoch at %d steps.'%ep_len, flush=True)\n",
    "\n",
    "                # if trajectory didn't reach terminal state, bootstrap value target\n",
    "                if timeout or epoch_ended:\n",
    "                    _, v, _ = actor_critic.step(o) \n",
    "                else:\n",
    "                    v = torch.tensor(0)\n",
    "                buf.finish_path(v)\n",
    "                o, ep_ret, ep_len = env.reset(), 0, 0\n",
    "\n",
    "\n",
    "        # Perform PPO update!\n",
    "        loss_pi, loss_v = update()\n",
    "\n",
    "        # Print progress\n",
    "        err = 8\n",
    "        print(\"iter \", epoch+1, \" -> loss (π): \", round(loss_pi, err), \"(v): \", round(loss_v, err),\n",
    "              \"| rewards: (train) \", round(np.mean(ret_train), err))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3ea66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppo(env, ac, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71d90a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1  -> loss (π):  -2.7e-07 (v):  0.02644246 | rewards: (train)  -0.86853135\n",
      "iter  2  -> loss (π):  3e-08 (v):  0.0020019 | rewards: (train)  -0.86811674\n",
      "iter  3  -> loss (π):  -1.2e-07 (v):  0.00090303 | rewards: (train)  -0.87428021\n",
      "iter  4  -> loss (π):  2.2e-07 (v):  0.0006856 | rewards: (train)  -0.87608922\n",
      "iter  5  -> loss (π):  -3.1e-07 (v):  0.00058834 | rewards: (train)  -0.87667501\n",
      "iter  6  -> loss (π):  -1.1e-07 (v):  0.00053695 | rewards: (train)  -0.87807024\n",
      "iter  7  -> loss (π):  -2e-07 (v):  0.00051347 | rewards: (train)  -0.88117307\n",
      "iter  8  -> loss (π):  -2.1e-07 (v):  0.00048704 | rewards: (train)  -0.87185085\n",
      "iter  9  -> loss (π):  -9e-08 (v):  0.00047727 | rewards: (train)  -0.87604135\n",
      "iter  10  -> loss (π):  -3.8e-07 (v):  0.00047594 | rewards: (train)  -0.87947857\n",
      "iter  11  -> loss (π):  -8e-08 (v):  0.00046976 | rewards: (train)  -0.87961018\n",
      "iter  12  -> loss (π):  -4.2e-07 (v):  0.00046133 | rewards: (train)  -0.87680125\n",
      "iter  13  -> loss (π):  -2.9e-07 (v):  0.00046797 | rewards: (train)  -0.88640946\n",
      "iter  14  -> loss (π):  -5.2e-07 (v):  0.00047167 | rewards: (train)  -0.89049411\n",
      "iter  15  -> loss (π):  3e-08 (v):  0.00047636 | rewards: (train)  -0.89830428\n",
      "iter  16  -> loss (π):  -4e-08 (v):  0.00046119 | rewards: (train)  -0.89013952\n",
      "iter  17  -> loss (π):  7.2e-07 (v):  0.00046874 | rewards: (train)  -0.89700097\n",
      "iter  18  -> loss (π):  3.6e-07 (v):  0.00046257 | rewards: (train)  -0.89322239\n",
      "iter  19  -> loss (π):  -1.8e-07 (v):  0.00046038 | rewards: (train)  -0.88977325\n",
      "iter  20  -> loss (π):  -1e-07 (v):  0.00046329 | rewards: (train)  -0.89419776\n",
      "iter  21  -> loss (π):  -1.5e-07 (v):  0.00046371 | rewards: (train)  -0.89374834\n",
      "iter  22  -> loss (π):  -1.5e-07 (v):  0.00046656 | rewards: (train)  -0.89627528\n",
      "iter  23  -> loss (π):  4e-08 (v):  0.00047637 | rewards: (train)  -0.9064945\n",
      "iter  24  -> loss (π):  1.9e-07 (v):  0.0004646 | rewards: (train)  -0.89613074\n",
      "iter  25  -> loss (π):  1e-07 (v):  0.00047208 | rewards: (train)  -0.90238696\n",
      "iter  26  -> loss (π):  -1.9e-07 (v):  0.0004675 | rewards: (train)  -0.89799714\n",
      "iter  27  -> loss (π):  4e-08 (v):  0.00047181 | rewards: (train)  -0.90177673\n",
      "iter  28  -> loss (π):  3.8e-07 (v):  0.00047484 | rewards: (train)  -0.90432298\n",
      "iter  29  -> loss (π):  1.1e-07 (v):  0.00046842 | rewards: (train)  -0.89840913\n",
      "iter  30  -> loss (π):  1.2e-07 (v):  0.0004711 | rewards: (train)  -0.90142977\n",
      "iter  31  -> loss (π):  3.9e-07 (v):  0.00047288 | rewards: (train)  -0.90216494\n",
      "iter  32  -> loss (π):  -1e-08 (v):  0.0004682 | rewards: (train)  -0.89831579\n",
      "iter  33  -> loss (π):  -5e-08 (v):  0.00047224 | rewards: (train)  -0.9013145\n",
      "iter  34  -> loss (π):  5e-08 (v):  0.00047123 | rewards: (train)  -0.90135759\n",
      "iter  35  -> loss (π):  2.1e-07 (v):  0.00047144 | rewards: (train)  -0.90096712\n",
      "iter  36  -> loss (π):  -1.3e-07 (v):  0.00046461 | rewards: (train)  -0.89539516\n",
      "iter  37  -> loss (π):  9e-08 (v):  0.00047363 | rewards: (train)  -0.90348166\n",
      "iter  38  -> loss (π):  1.4e-07 (v):  0.0004744 | rewards: (train)  -0.90409869\n",
      "iter  39  -> loss (π):  -1.8e-07 (v):  0.00047166 | rewards: (train)  -0.90331745\n",
      "iter  40  -> loss (π):  -1.1e-07 (v):  0.00047432 | rewards: (train)  -0.90522242\n",
      "iter  41  -> loss (π):  5e-08 (v):  0.00048101 | rewards: (train)  -0.91087639\n",
      "iter  42  -> loss (π):  -2.8e-07 (v):  0.00045373 | rewards: (train)  -0.88583809\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b3baaa0b4644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# ... do something ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mppo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8848c2722b0a>\u001b[0m in \u001b[0;36mppo\u001b[0;34m(env, actor_critic, args, lam, target_kl, clip_ratio, pi_lr, vf_lr)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mep_len\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mnext_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DynamicGraphPlanning/actor/actor_critic.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TODO: should we be doing this?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mlogp_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_prob_from_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#.sum(-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp_a\u001b[0m \u001b[0;31m#a.numpy(), v.numpy(), logp_a.numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlpyt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DynamicGraphPlanning/actor/actor_critic.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ptr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mn_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlpyt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DynamicGraphPlanning/actor/collision_avoidance.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upper_bound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lower_bound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upper_bound\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lower_bound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlpyt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/victorialena_pyg/tmp8v5a1bve.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlpyt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DynamicGraphPlanning/gatv2_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;31m#out.mean(dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ``` python \n",
    "import cProfile, pstats, io\n",
    "from pstats import SortKey\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "# ... do something ...\n",
    "ppo(env, ac, args)\n",
    "\n",
    "pr.disable()\n",
    "s = io.StringIO()\n",
    "sortby = SortKey.CUMULATIVE\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "ps.print_stats()\n",
    "print(s.getvalue())\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e3e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rlpyt] *",
   "language": "python",
   "name": "conda-env-rlpyt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
