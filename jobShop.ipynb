{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "945f625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86bd8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3a2af2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.spaces import MultiDiscrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ced15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9133d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_queues(n: int, beta: float = 0.8):\n",
    "    free = [True]*n\n",
    "    out = []\n",
    "    for i in np.random.permutation(n):\n",
    "        if not free[i]:\n",
    "            continue\n",
    "        free[i] = False\n",
    "        \n",
    "        while np.random.rand() < beta:\n",
    "            try:\n",
    "                j = np.random.choice(np.where(free)[0])\n",
    "            except:\n",
    "                return out\n",
    "            free[j] = False\n",
    "            out.append([i, j])\n",
    "            i = j\n",
    "    return out\n",
    "\n",
    "def count_q_length(_from, _to, n):\n",
    "    counts, prev_counts = torch.zeros(n), torch.zeros(n)\n",
    "    counts[_from] = 1\n",
    "    while not all(counts == prev_counts):\n",
    "        prev_counts = deepcopy(counts)\n",
    "        counts[_from] = counts[_to]+1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "befbbf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "_from, _to = torch.tensor(get_random_queues(10)).T        \n",
    "graph_data = {('job', 'precede', 'job'): (_from, _to), # A ---before---> B\n",
    "              ('job', 'next', 'job'): (torch.tensor([0]), torch.tensor([0])), # jobshop queue\n",
    "              ('worker', 'processing', 'job'): (torch.tensor([0]), torch.tensor([0])) # nothing is scheduled\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3736301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.heterograph(graph_data, num_nodes_dict={'worker':2 , 'job':10})\n",
    "g.remove_edges(0, 'processing')\n",
    "g.remove_edges(0, 'next')\n",
    "\n",
    "g.nodes['job'].data['hv'] = torch.rand(10, 7) #TODO\n",
    "g.nodes['worker'].data['he'] = torch.rand(2, 3) #torch.eye(2) -- one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "319209ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_readout_graph(g, etype):\n",
    "    \"\"\" etype = use .canonical_etypes() \"\"\"\n",
    "    utype, _, vtype = etype\n",
    "    nu, nv = g.num_nodes(utype), g.num_nodes(vtype)\n",
    "    src, dst = g.nodes(utype).repeat_interleave(nv), g.nodes(vtype).repeat(nu)\n",
    "    \n",
    "    return dgl.heterograph({etype: (src, dst)},\n",
    "                           num_nodes_dict={utype: nu, vtype: nv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dc7d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "class dotProductPredictor(nn.Module):\n",
    "    \"\"\" returns scores for each job (row) per worker (col)\"\"\"\n",
    "    def forward(self, graph, hv, he, _etype):\n",
    "        # hv contains the node representations computed from the GNN\n",
    "        utype, etype, vtype = _etype\n",
    "        with graph.local_scope():\n",
    "            graph.nodes[vtype].data['hv'] = hv\n",
    "            graph.nodes[utype].data['he'] = he\n",
    "            graph.apply_edges(fn.u_dot_v('he', 'hv', 'score'), etype=etype)\n",
    "            return graph.edges[etype].data['score'].view(-1, hv.shape[0]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25581e4b",
   "metadata": {},
   "source": [
    "```python\n",
    "g.nodes('job')\n",
    "g.ntypes\n",
    "g.etypes\n",
    "g.canonical_etypes\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa2afea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class agent(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, rel_names):\n",
    "        super().__init__()\n",
    "        self.sage = RGCN(in_features, hidden_features, out_features, rel_names)\n",
    "        self.pred = dotProductPredictor()\n",
    "    \n",
    "    def forward(self, g, x, etype):        \n",
    "        hv = self.sage(g, x)\n",
    "        he = g.nodes['worker'].data['he']\n",
    "        rg = construct_readout_graph(g, ('worker', 'processing', 'job'))\n",
    "        return self.pred(rg, hv, he, ('worker', 'processing', 'job'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02b003ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class jobShopScheduling(gym.Env):\n",
    "    \"\"\"\n",
    "    ### Description\n",
    "    Learning to schedule a successful sequence of “job” to multiple workers respecting given constraints. \n",
    "    \n",
    "    ### Action Space\n",
    "    By adding an edge from a worker to an unscheduled job, the job gets queued to that thread.\n",
    "    The resulting sequence can not be chnaged in hindsight.\n",
    "    \n",
    "    ### State Space    \n",
    "    A disjunctive heterogeneous graph g = (V, C U D). Each node represents a “job” or a “worker”. \n",
    "    Edges in C denote succession requirements for jobs, edges in D denotes which jobs were assigned to \n",
    "    which worker. \n",
    "    \n",
    "    ### Rewards\n",
    "    The system recieves a positive unit reward for each executed job. And a penalty per time step.\n",
    "    \n",
    "    ### Starting State\n",
    "    A random set of n jobs, including time requirements and succession constraints, e.g., task i requires \n",
    "    completion of task j.\n",
    "    \n",
    "    ### Episode Termination\n",
    "    The episode terminates when all jobs have been scheduled. Then the action space has schunken to size 0.\n",
    "    The final reward tallies up the remaining rewards to be versed (w/o time discounting).\n",
    "    \n",
    "    ### Arguments\n",
    "    No additional arguments are currently supported.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, njobs: int, nworkers: int):\n",
    "        self._njobs = njobs\n",
    "        self._nworkers = nworkers\n",
    "        self._jfeat = 7\n",
    "        self._wfeat = 3\n",
    "        self._dt = 0.1\n",
    "        self._time_penalty = -.1\n",
    "        \n",
    "        self._state = None\n",
    "        \n",
    "    def reward(self, a):\n",
    "        assert False, \"Not implemented. Do not call.\"\n",
    "    \n",
    "    def terminal(self):\n",
    "        # Terminal state is reached when all the jobs have been scheduled. |A| is zero.\n",
    "        return all(self._state.nodes['job'].data['hv'][:, 3] == 1)\n",
    "    \n",
    "    def worker_features(self):\n",
    "        return ('n queued', 'expected run time', 'efficiency rate')\n",
    "    \n",
    "    def job_features(self):\n",
    "        return ('time req', \n",
    "                'completion%', #1\n",
    "                'nr of child nodes', #2 \n",
    "                'status (one hot: scheduled, processing, finished)', #3-4-5\n",
    "                'remaining time') #6\n",
    "    \n",
    "    def valid_action(self, a):\n",
    "        _, j = a\n",
    "        return self._state.nodes['job'].data['hv'][j, 3] == 0\n",
    "    \n",
    "    def check_job_requirements(self, j):\n",
    "        # Return True if no incoming edges from preceding job requirements.\n",
    "        _, dst = self._state.edges(etype='precede')\n",
    "        return all(dst != j)\n",
    "    \n",
    "    def rollout(self, verbose=False):\n",
    "        # Return number of jobs complete if we just waited until all workers exit (done of gridlock)\n",
    "        # Does not take into account discount factor!\n",
    "        state_hv = deepcopy(self._state.nodes['job'].data['hv'])\n",
    "        state_he = deepcopy(self._state.nodes['worker'].data['he'])\n",
    "        \n",
    "        jdone = state_hv[:, 5] == 1\n",
    "        \n",
    "        reward = 0\n",
    "        src, dst = deepcopy(self._state.edges(etype='processing'))\n",
    "        sreq, dreq = deepcopy(self._state.edges(etype='precede'))\n",
    "        \n",
    "        while True:\n",
    "            idx = [dst[src==w][0].item() for w in src.unique().tolist()]\n",
    "            idx = [j for j in idx if all(jdone[sreq[dreq==j]])]\n",
    "            if len(idx) == 0:\n",
    "                break # gridlock\n",
    "            \n",
    "            # get smallest remaining time for idx. -(.dt)\n",
    "            j = idx[state_hv[idx, 6].argmin().item()]\n",
    "            if verbose:\n",
    "                print(\"executing job\", j, \"on worker\", src[dst==j].item())\n",
    "            jdone[j] = True\n",
    "            reward += 1 - state_hv[j, 6]\n",
    "            state_hv[idx, 6] -= state_hv[j, 6] #mark that job as done\n",
    "            \n",
    "            # remove job from queue\n",
    "            src = src[dst!=j]\n",
    "            dst = dst[dst!=j]\n",
    "                \n",
    "        return reward, all(jdone)\n",
    "        \n",
    "    \n",
    "    def step(self, a):\n",
    "        assert self.valid_action(a), \"Invalid action taken.\"\n",
    "        \n",
    "        src, dst, cnts = self._state.edges('all', etype='processing')\n",
    "        \n",
    "        \"\"\" \n",
    "        1) Schedule job j for worker w: \n",
    "            a) Find last job scheduled for worker w, add edge from end of queue to new job j. \n",
    "            b) Add edge from w to j. \n",
    "            c) Update worker info (queue length, run time estimate).\n",
    "            d) Mark job as scheduled.\n",
    "        \"\"\"\n",
    "        w, j = a\n",
    "        if w in src:\n",
    "            _i = dst[src==w][-1].item() # add to end of q -- last edge added\n",
    "            self._state.add_egde(_i, j, etype='next')        \n",
    "        self._state.add_egde(w, j, etype='processing')\n",
    "        \n",
    "        state_hv = deepcopy(self._state.nodes['job'].data['hv'])\n",
    "        state_he = deepcopy(self._state.nodes['worker'].data['he'])\n",
    "        \n",
    "        state_he[w, 0] += 1. # add job to work queue length\n",
    "        state_he[w, 1] += state_hv[j, 0] # update worker' run time estimate\n",
    "        state_hv[j, 3] = 1. # mark as scheduled\n",
    "        \n",
    "        \"\"\" 2) Assure the first job in queue is being processed at this time step. \"\"\"\n",
    "        _, req = self._state.edges(etype='precede')\n",
    "        newidx = [dst[src==w][0].item() for w in src.unique().tolist()]\n",
    "        newidx = [j for j in newidx if j in req]\n",
    "        state_hv[newidx, 4] = 1 # set to processing (but completion % remain 0)\n",
    "\n",
    "        \"\"\" \n",
    "        3) Update feature vectors:\n",
    "            a) Progress time for node features: remaining time, completion % for jobs and workers\n",
    "            b) Update info around terminal jobs, and remove processing edge if job has terminated.\n",
    "            c) Remove next and precede edges for terminated jobs. \n",
    "        \"\"\"\n",
    "        # a\n",
    "        processing_mask = prev_state_hv[:, 4] == 1\n",
    "        state_hv[processing_mask, 6] = torch.maximum(state_hv[processing_mask, 6]-self._dt, torch.zeros(nj)) # update remaining time\n",
    "        state_hv[processing_mask, 1] = torch.clamp(1-torch.div(state_hv[processing_mask, 0],\n",
    "                                                               state_hv[processing_mask, 6]), \n",
    "                                                   min=0, max=1) # update completion %\n",
    "        state_he[:, 1] = torch.maximum(state_he[:, 1]-self._dt, torch.zeros(ne)) # update remaining time\n",
    "        \n",
    "        # b\n",
    "        state_hv[processing_mask, 5] = state_hv[processing_mask, 1] == 1 # mark terminal\n",
    "        state_hv[processing_mask, 4] = ~state_hv[processing_mask, 5] # if terminal, job no longer processing        \n",
    "        idx = torch.where(processing_mask)[0][torch.where(state_hv[processing_mask, 5])[0]].tolist() # job ids just terminated\n",
    "        if len(idx):\n",
    "            widx = [(j in idx) for j in dst]\n",
    "            state_he[src[widx], 0] -= 1 # remove job from job count\n",
    "            self._state.remove_egdes(cnts[widx].tolist(), 'processing') # delete those edges?\n",
    "        \n",
    "        # c\n",
    "        src, dst, cnts = self._state.edges('all', etype='next')\n",
    "        ptridx = torch.cat([cnts[src == j].item() for j in idx if j in src]) # this works because it is a queue: unique next node\n",
    "        self._state.remove_egdes(ptridx.tolist(), 'next')\n",
    "        \n",
    "        src, dst, cnts = self._state.edges('all', etype='precede')\n",
    "        jidx = [(j in idx) for j in src]\n",
    "        self._state.remove_egdes(cnts[jidx].tolist(), 'precede') # delete those edges?\n",
    "                \n",
    "        \"\"\" 5) Update feature vectors. \"\"\"\n",
    "        self._state.nodes['job'].data['hv'] = state_hv\n",
    "        self._state.nodes['worker'].data['he'] = state_he\n",
    "                \n",
    "        \"\"\" 6) Compute reward and terminal state. \"\"\"\n",
    "        done = self.terminal()\n",
    "        if done:\n",
    "            n_terminal = len(idx)\n",
    "            reward = self._time_penalty + n_terminal\n",
    "        else:\n",
    "            reward, success = self.rollout()\n",
    "        \n",
    "        return deepcopy(self._state), reward, done, {}\n",
    "\n",
    "    def reset(self, seed: int = None, topology: str = 'random'):\n",
    "        if not seed == None:\n",
    "            super().reset(seed=seed)\n",
    "        \n",
    "        nw, nj = self._nworkers, self._njobs\n",
    "        _from, _to = torch.tensor(get_random_queues(nj)).T\n",
    "        graph_data = {\n",
    "           ('job', 'pecede', 'job'): (_from, _to), # A ---before---> B\n",
    "           ('job', 'next', 'job'): (torch.tensor([0]), torch.tensor([0])), # jobshop queue\n",
    "           ('worker', 'processing', 'job'): (torch.tensor([0]), torch.tensor([0])) # nothing is scheduled\n",
    "        }\n",
    "        \n",
    "        self._state = dgl.heterograph(graph_data, num_nodes_dict={'worker': nw, 'job': nj})\n",
    "        # hack: can not init null vector for edges\n",
    "        self._state.remove_edges(0, 'processing')\n",
    "        self._state.remove_edges(0, 'next')\n",
    "        \n",
    "        times = 0.1*torch.randint(10, (nj,1)) # torch.rand(nj,1)\n",
    "        counts = count_q_length(_from, _to, nj)\n",
    "        self._state.nodes['job'].data['hv'] = torch.cat((times, torch.zeros(nj, 1), counts, torch.zeros(nj, 3), times), 1)\n",
    "        self._state.nodes['worker'].data['he'] = torch.cat((torch.zeros(nw,2), torch.ones(nw,1)), 1)\n",
    "        \n",
    "        return deepcopy(self._state)\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "        import networkx as nx\n",
    "        import matplotlib.pyplot as plt\n",
    "        G = dgl.to_homogeneous(g).to_networkx()\n",
    "        options = { 'node_color': 'black', 'node_size': 20, 'width': 1,  }\n",
    "        nx.draw(G, **options)\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def seed(self, n: int):\n",
    "        super().reset(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f5f7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rlpyt] *",
   "language": "python",
   "name": "conda-env-rlpyt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
